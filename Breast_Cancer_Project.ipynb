{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDKwVwNoZb1s"
      },
      "outputs": [],
      "source": [
        "#Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I imported the necessary libraries:\n",
        "\n",
        "Pandas is used for data manipulation\n",
        "\n",
        "Numpy is used to work on arrays and numerical data"
      ],
      "metadata": {
        "id": "eWnh-VJ8TZJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import data from gdrive to colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AL-WSTGJZ4Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Through the google colab library use the function drive to give the notebook permission to access my files"
      ],
      "metadata": {
        "id": "DuTDgkWWT7Wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load dataset\n",
        "cancer = pd.read_csv('/content/drive/My Drive/data.csv')"
      ],
      "metadata": {
        "id": "QYFljLajZ-6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using my given variable titanic I manipulated the dataset from my Google drive to the notebook"
      ],
      "metadata": {
        "id": "DBXxCE1AUE_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA EXPLORATION**"
      ],
      "metadata": {
        "id": "nZaxkaIJeGsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#view data\n",
        "cancer.head(10)"
      ],
      "metadata": {
        "id": "c4-9v7fRaadY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viewing the first 10 rows in my data"
      ],
      "metadata": {
        "id": "tf9AjMKkUZjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Structure of the data\n",
        "cancer.info()"
      ],
      "metadata": {
        "id": "CGLG-TZCkFj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking a summary of the data(How many rows in each column and their datatypes and non-null counts)"
      ],
      "metadata": {
        "id": "fijs7X85VHns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#View shape of data\n",
        "cancer.shape"
      ],
      "metadata": {
        "id": "cUeEdhrWeiPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the number of rows and columns in our data"
      ],
      "metadata": {
        "id": "3eA-nD7EU-25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#View elements in target variable diagnosis\n",
        "cancer['diagnosis'].unique()"
      ],
      "metadata": {
        "id": "vHZl5ySibSEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "View elements in the the column diagnosis"
      ],
      "metadata": {
        "id": "SZ3An8n_Vrnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#View datatypes\n",
        "cancer.dtypes"
      ],
      "metadata": {
        "id": "g-jhRQRDbyYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the data types of each column"
      ],
      "metadata": {
        "id": "L0k58McOWAtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for nulls\n",
        "cancer.isnull().sum()"
      ],
      "metadata": {
        "id": "rJhM0bvFdGbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for nulls in the dataset and remove through data cleaning"
      ],
      "metadata": {
        "id": "ZNpBEeG_WcB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for duplicates\n",
        "cancer.duplicated().sum()"
      ],
      "metadata": {
        "id": "e24c07n9dhL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if the data had duplicates in which case there wasn't"
      ],
      "metadata": {
        "id": "kWB-Q4osWyOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#View statistical data\n",
        "cancer.describe()"
      ],
      "metadata": {
        "id": "VjY43N6ldwrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "View a summary of the statistics of the data"
      ],
      "metadata": {
        "id": "qADWhVfNW_kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Categorizing columns\n",
        "categorical_columns = []\n",
        "non_categorical_columns = []\n",
        "for column in cancer.columns:\n",
        "  if cancer[column].dtype == 'object':\n",
        "    categorical_columns.append(column)\n",
        "  else:\n",
        "    non_categorical_columns.append(column)\n",
        "print(\"Categorical columns\")\n",
        "print(categorical_columns)\n",
        "print(\"Non_categorical columns\")\n",
        "print(non_categorical_columns)"
      ],
      "metadata": {
        "id": "1DtHc_k2gGj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grouping our data to check for categorical and non categorical dtypes"
      ],
      "metadata": {
        "id": "wZ6EEV_PXMGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA CLEANING**"
      ],
      "metadata": {
        "id": "gIhsjML4fTcc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since there are nulls in column \"Unnamed: 32\", clean the data by removing the nulls"
      ],
      "metadata": {
        "id": "nH4E4U8fXRYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#View sum of nulls in Unnamed: 32\n",
        "cancer['Unnamed: 32'].isnull().sum()"
      ],
      "metadata": {
        "id": "tXvzI-D4e7tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove nulls\n",
        "cancer['Unnamed: 32'] = cancer['Unnamed: 32'].fillna(0)\n",
        "cancer['Unnamed: 32'].isnull().sum()"
      ],
      "metadata": {
        "id": "qgVnNJTGhAlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove outliers\n",
        "#list of columns to check outliers\n",
        "columns = [ 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32']\n",
        "#create a funtion to clean outliers\n",
        "def clean_outliers(column):\n",
        "  mean = cancer[column].mean()\n",
        "  std = cancer[column].std()\n",
        "  threshold = 3\n",
        "  lower_limit = mean - threshold * std\n",
        "  upper_limit = mean + threshold * std\n",
        "  return cancer[(cancer[column] >= lower_limit) & (cancer[column] <= upper_limit)]\n",
        "\n",
        "for column in columns:\n",
        "   new_cancer = clean_outliers(column)\n",
        "new_cancer.shape"
      ],
      "metadata": {
        "id": "IWnhHTnriAGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cancer.shape"
      ],
      "metadata": {
        "id": "kBRwrlJplb2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data had no outliers since the shape of the data remained the same after determining our threshold"
      ],
      "metadata": {
        "id": "NiBj-En1mlFX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA PREPROCESSING**\n",
        "Feature engineering\n",
        "\n",
        "Transform raw data from our data to features usable in machine learning.\n",
        "\n",
        "Encode the relevant data to be used"
      ],
      "metadata": {
        "id": "xpDIVaH7m2Ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import libraries for encoding\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "UNyw1JQqcTb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding the relevant categorical columns\n",
        "#encoding diagnosis\n",
        "cancer['diagnosis'].unique()\n",
        "cancer['diagnosis'] = cancer['diagnosis'].map({'M':0,'B':1})\n",
        "print(cancer['diagnosis'].unique())"
      ],
      "metadata": {
        "id": "3EL1qWztdHeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL BUILDING**"
      ],
      "metadata": {
        "id": "GI-oRWuld5ID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since diagnosis is a binary classification, we will use logistic,random forest or decision trees"
      ],
      "metadata": {
        "id": "s1tseCkgeA9D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic regression**"
      ],
      "metadata": {
        "id": "F1LySL0kiRh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import libraries for training and testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "YYBaTYHxfLUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Giving x and y variables\n",
        "x = cancer.drop('diagnosis',axis=1)\n",
        "y = cancer['diagnosis']\n",
        "#train and test the data\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=50)\n",
        "#give the model a variable\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "#fit the model\n",
        "model.fit(x_train,y_train)\n",
        "#make predictions\n",
        "y_pred = model.predict(x_test)\n",
        "#Get the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "Oy5lIWxFdkWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Train the data at 80% and test it at 20%\n",
        "*   Random_state is a parameter used in shuffling the data before splitting it. The more it increases the better your model performs and in this case the best RS was 50\n",
        "*Give the model a variable\n",
        "*Fit model and make a prediction of the outcome you need\n",
        "*Get the accuracy of the prediction"
      ],
      "metadata": {
        "id": "q3ZZa7xBakeR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model accuracy was 34 % meaning we can't use Logistic regression for prediction and have to use an alternative model"
      ],
      "metadata": {
        "id": "iczlBNSnbXhq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random forest**"
      ],
      "metadata": {
        "id": "fFDpBWiKiWt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Libraries for random forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "3U8iamWpfU_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Giving x and y variables\n",
        "x = cancer.drop('diagnosis',axis=1)\n",
        "y = cancer['diagnosis']\n",
        "#train and test the data\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=50)\n",
        "#give the model a variable\n",
        "model = RandomForestClassifier(criterion = 'gini', max_depth = 3,random_state=0)\n",
        "#fit the model\n",
        "model.fit(x_train,y_train)\n",
        "#make predictions\n",
        "y_pred = model.predict(x_test)\n",
        "#Get the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "Klazk6Muikwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Classifier was the most accurate model with an accuracy of 95% and now we can tune it to find a better performance of the same model."
      ],
      "metadata": {
        "id": "pvEXK2kNbuG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Tuning**"
      ],
      "metadata": {
        "id": "rUYN-BIajBop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#get the param grid\n",
        "param_grid = {\n",
        "    'min_samples_split': [2, 3, 4],\n",
        "    'min_samples_leaf': [1, 2, 3]\n",
        "}\n",
        "#create a model variable\n",
        "mod = RandomForestClassifier(criterion='gini',max_depth=3)\n",
        "#perform grid search\n",
        "grid_search = GridSearchCV(mod, param_grid, cv=5)\n",
        "#fit the grid search\n",
        "grid_search.fit(x_train, y_train)\n",
        "best_params = grid_search.best_params_\n",
        "print(best_params)"
      ],
      "metadata": {
        "id": "TiulkKTejJAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Import the gridsearchcv funtion from the sklearn model selection library which will help in finding the best parameters to use\n",
        "\n",
        "* Make a library of the parameter of which will be used to find the best parameter\n",
        "* cv stands for cross validdation in which the data will be split 5 times and trained/tested to different hyperparameters\n",
        "*Fit the grid search to the data.\n",
        "*After the grid search, using the function best_params_, find the best parameters in the parameter grid"
      ],
      "metadata": {
        "id": "H5lznOoXcSRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "#Original fit and prediction\n",
        "model.fit(x_train,y_train)\n",
        "y_pred = model.predict(x_test)\n",
        "#name the retrained model\n",
        "best_model =RandomForestClassifier(**best_params)\n",
        "best_model.fit(x_train,y_train)\n",
        "y_pred_best = best_model.predict_proba(x_test)[:, 1]\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "\n",
        "roc_auc_score = roc_auc_score(y_test, y_pred_best)\n",
        "\n",
        "print(f\"Accuracy score: {accuracy}\")\n",
        "print(f\"ROC AUC SCORE: {roc_auc_score}\")"
      ],
      "metadata": {
        "id": "SAzfz4c6jtdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Import ROC AUC Score to evaluate performance of the new model\n",
        "* Fit the new model to the data\n",
        "* Make the prediction of the new outcome\n",
        "* Get the accuracy and roc_auc_score and compare the model performance before and after tuning the model"
      ],
      "metadata": {
        "id": "ANKrYQwkc3US"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the best model fit for our data since it gave us a model performance of 99.5% after tuning"
      ],
      "metadata": {
        "id": "QdU4XiL-j-NK"
      }
    }
  ]
}